# Classifica√ß√£o Bin√°ria Neuro-Simb√≥lica: Gatos vs. Cachorros com LTNtorch

Este projeto implementa um classificador bin√°rio de imagens (Gato vs. Cachorro) utilizando uma abordagem **Neuro-Simb√≥lica** baseada no framework **Logic Tensor Networks (LTN)**.

Diferente das abordagens tradicionais de Deep Learning que minimizam o erro entre um r√≥tulo e uma predi√ß√£o, este modelo aprende **maximizando a satisfa√ß√£o de regras l√≥gicas** definidas em uma Base de Conhecimento.
---
### integrantes
* Antonio Lucas
* Breno
* Caio
* Lucas da Silva Moura
* Luiz Felipe Nery Soares
* Sarah Campos Fernandes Lima
* Rafael Emanuel Dantas Viana
* Victor Jos√© Nunes Kossman
---
## üß† O Conceito: Logic Tensor Networks (LTN)

O LTN integra o aprendizado profundo (Redes Neurais) com o racioc√≠nio l√≥gico (L√≥gica de Primeira Ordem Fuzzy). O processo se baseia em tr√™s pilares principais:

1.  **L√≥gica Real (Real Logic):** Uma linguagem onde os s√≠mbolos l√≥gicos s√£o interpretados como tensores (dados) e fun√ß√µes diferenci√°veis (redes neurais).
2.  **Grounding (Aterramento/Ancoragem):** O mapeamento dos dados reais para os s√≠mbolos l√≥gicos. [cite_start]Por exemplo, conectar um conjunto de imagens √† vari√°vel l√≥gica $x$.
3.  **Aprendizado via Satisfa√ß√£o:** O treinamento busca ajustar os pesos da rede neural para que as f√≥rmulas l√≥gicas da base de conhecimento sejam verdadeiras (valor de verdade pr√≥ximo de 1).

## üìã O Problema e a Modelagem L√≥gica

**Objetivo:** Classificar corretamente se uma imagem √© de um **Cachorro** ou de um **Gato** usando o dataset CIFAR-10.

### A Base de Conhecimento ($\mathcal{K}$)

Definimos um predicado $Dog(x)$ que representa uma Rede Neural (CNN).Esta rede recebe uma imagem $x$ e retorna a probabilidade (grau de verdade) de ser um cachorro.

O modelo √© treinado para satisfazer dois axiomas l√≥gicos fundamentais:

1.  **Axioma Positivo:** "Para toda imagem de cachorro ($x_{dog}$), o predicado $Dog$ deve ser verdadeiro."
    $$\forall x_{dog} (Dog(x_{dog}))$$

2.  **Axioma Negativo:** "Para toda imagem de gato ($x_{cat}$), o predicado $Dog$ **N√ÉO** deve ser verdadeiro."
    $$\forall x_{cat} (\neg Dog(x_{cat}))$$

### Fun√ß√£o de Perda (Loss)

A fun√ß√£o de perda n√£o compara r√≥tulos diretamente. Ela √© derivada da satisfa√ß√£o agregada da base de conhecimento ($SatAgg$):

$$\mathcal{L} = 1 - SatAgg(\mathcal{K})$$

O otimizador trabalha para minimizar essa perda, o que equivale a maximizar a verdade das regras l√≥gicas.

## üõ†Ô∏è Arquitetura e Implementa√ß√£o

[cite_start]O c√≥digo est√° estruturado nas seguintes etapas, conforme proposto na documenta√ß√£o do LTNtorch[cite: 19, 189]:

### 1. Prepara√ß√£o dos Dados
* **Dataset:** CIFAR-10.
* **Filtragem:** Seleciona-se apenas as classes √≠ndice 3 (Gatos) e 5 (Cachorros).
* **Normaliza√ß√£o:** Imagens convertidas para tensores normalizados.
* **Separa√ß√£o:** Os dados s√£o divididos em dois grupos (`cats_data` e `dogs_data`) para permitir o *grounding* correto das vari√°veis l√≥gicas.

### 2. O Predicado (Rede Neural)
Uma **CNN Simples** √© utilizada como a "intelig√™ncia" por tr√°s do predicado $Dog$.
* **Entrada:** Imagens 32x32 pixels (3 canais).
* **Estrutura:** 2 camadas convolucionais + Max Pooling + 3 camadas lineares.
* **Sa√≠da:** Um √∫nico neur√¥nio com ativa√ß√£o **Sigmoid**, garantindo um valor de verdade no intervalo fuzzy $[0, 1]$.

### 3. Operadores Fuzzy
O LTN substitui operadores booleanos por operadores difusos diferenci√°veis:
* **Conectivo NOT ($\neg$):** Nega√ß√£o padr√£o ($1 - x$).
* **Quantificador FORALL ($\forall$):** Agregador baseado em erro m√©dio (*p-mean error*).

### 4. Loop de Treinamento
A cada √©poca:
1.  Amostra-se um batch de c√£es e um de gatos.
2.  **Grounding:** Cria-se vari√°veis LTN (`var_dog`, `var_cat`) associadas √†s imagens.
3. **Avalia√ß√£o:** As f√≥rmulas $\forall x_{dog} Dog(x)$ e $\forall x_{cat} \neg Dog(x)$ s√£o calculadas.
4. **Backpropagation:** O gradiente flui atrav√©s da estrutura l√≥gica at√© os pesos da CNN para maximizar a satisfa√ß√£o.

## üöÄ Como Executar

### Pr√©-requisitos

```bash
pip install torch torchvision ltntorch matplotlib numpy
```
### Exemplo
```python
# Exemplo de sa√≠da esperada ap√≥s o treino:
# Predicado Dog(imagem_cachorro) = 0.9991 (Esperado: ~1.0)
# Predicado Dog(imagem_gato)     = 0.0277 (Esperado: ~0.0)
